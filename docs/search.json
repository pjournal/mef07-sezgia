[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sezgi Ayhan Progress Journal",
    "section": "",
    "text": "Introduction\n\nThis progress journal covers Sezgi Ayhan during their term at BDA 503 Fall 2023.\nEach section is an assignment or an individual work.\nMy Repository"
  },
  {
    "objectID": "assignment1.html#about-me",
    "href": "assignment1.html#about-me",
    "title": "Assignment 1",
    "section": "1.1 About me",
    "text": "1.1 About me\nSezgi Ayhan, as an Investor Relations Coordinator, I leverage my 12 years of experience and expertise in capital markets, corporate finance, and ESG issues to communicate effectively with institutional investors and analysts. I aim to enhance the quality of datasets and their visualization in materials presented to investors and conduct an analysis to measure the impact of company disclosures on investors’ decision making process. Most importantly, I seek a deeper understanding of the algorithmic trading and traders’ behaviors."
  },
  {
    "objectID": "assignment1.html#creating-data-science-portfolio-with-quarto",
    "href": "assignment1.html#creating-data-science-portfolio-with-quarto",
    "title": "Assignment 1",
    "section": "1.2 Creating Data science Portfolio with Quarto",
    "text": "1.2 Creating Data science Portfolio with Quarto\nThis is the video I selected from the tutorial collection:\n\nlibrary(\"vembedr\")\nembed_url(\"https://www.youtube.com/watch?v=xtSFXtDf4cM&list=PL9HYL-VRX0oTOK4cpbCbRk15K2roEgzVW&index=6\")\n\n\n\n\n\n\n\n\nDeepsha Menghani created a blog about herself using quarto, conceptually very similar to this assignment. She designed her page with a navigation toolbar and positioned each sections. She used jolla template in about.qmd to create about page, inserting images and links with icons.. She created projects.qmd and listings with contents of posts which is a directory defined for this blog. She further personalized the page with customized themes and used code tools."
  },
  {
    "objectID": "assignment1.html#dataset",
    "href": "assignment1.html#dataset",
    "title": "Assignment 1",
    "section": "1.3 Dataset",
    "text": "1.3 Dataset\nThe dataset I’ve selected for presentation on this page is a historical dataset pertaining to the modern Olympic Games. It comprises 15 distinct data variables designed for exploration and analysis.\n\nID - Unique number for each athlete\nName - Athlete’s name\nSex - M or F\nAge - Integer\nHeight - In centimeters\nWeight - In kilograms\nTeam - Team name\nNOC - National Olympic Committee 3-letter code\nGames - Year and season\nYear - Integer\nSeason - Summer or Winter\nCity - Host city\nSport - Sport\nEvent - Event\nMedal - Gold, Silver, Bronze, or NA\n\nSource Link\nHere’s a code that displays athletes who are 10 years old\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nevent &lt;- read.csv(\"./athlete_events.csv\")\nfilter(event, Age == 10)\n\n     ID               Name Sex Age Height Weight                          Team\n1 71691 Dimitrios Loundras   M  10     NA     NA Ethnikos Gymnastikos Syllogos\n  NOC       Games Year Season   City      Sport\n1 GRE 1896 Summer 1896 Summer Athina Gymnastics\n                                  Event  Medal\n1 Gymnastics Men's Parallel Bars, Teams Bronze"
  },
  {
    "objectID": "assignment1.html#some-r-posts",
    "href": "assignment1.html#some-r-posts",
    "title": "Assignment 1",
    "section": "1.4 Some R Posts",
    "text": "1.4 Some R Posts\n\n1.4.1 Pareto Chart\nA Pareto chart is a type of bar chart that shows the frequency of different categories in a dataset, ordered by frequency from highest to lowest.\n\nlibrary(qcc)\n\nPackage 'qcc' version 2.7\n\n\nType 'citation(\"qcc\")' for citing this R package in publications.\n\n#Create a data frame with the product and its count\ndf &lt;- data.frame(\n  product = c(\"Office desks\", \"Chairs\", \"Filing cabinets\", \"Bookcases\"),\n  count = c(100, 80, 70, 60)\n)\n\n# Create the Pareto chart\npareto.chart(df$count, main = \"Pareto Chart of Product Sales\")\n\n\n\n\n   \nPareto chart analysis for df$count\n    Frequency Cum.Freq. Percentage Cum.Percent.\n  A 100.00000 100.00000   32.25806     32.25806\n  B  80.00000 180.00000   25.80645     58.06452\n  C  70.00000 250.00000   22.58065     80.64516\n  D  60.00000 310.00000   19.35484    100.00000\n\n\n\n\n1.4.2 Bubble Chart\nBubble charts are a great way to visualize data with three dimensions. The size of the bubbles represents a third variable, which can be used to show the importance of that variable or to identify relationships between the three variables.\n\n# Load ggplot2 library\nlibrary(ggplot2)\n\n# Sample data\ncars &lt;- mtcars\ncars$name &lt;- rownames(cars)\n\n# Generate random data\nset.seed(123)\ndata &lt;- data.frame(\n  x = rnorm(10),\n  y = rnorm(10),\n  size = runif(10, min = 5, max = 20)\n)\n\n# Create a bubble chart\nggplot(data, aes(x, y, size = size)) +\n  geom_point() +\n  scale_size_continuous(range = c(3, 10)) +\n  labs(\n    title = \"Basic Bubble Chart\", \n    x = \"X-Axis\", \n    y = \"Y-Axis\",\n    size = \"Y\") +\n  theme_minimal()\n\n\n\n\n\n\n1.4.3 Creating a List\nA list in R is used to gather a variety of objects under one name (that is, the name of the list) in an ordered way. These objects can be matrices, vectors, data frames, even other lists, etc. It is not even required that these objects are related to each other in any way.\n\n# Vector with numerics from 1 up to 4\nmy_vector &lt;- 1:4 \n\n# Matrix with numerics from 1 up to 9\nmy_matrix &lt;- matrix(1:9, ncol = 3)\n\nlibrary(qcc)\n#Create a data frame with the product and its count\n\noffice_df &lt;- data.frame(\n  product = c(\"Office desks\", \"Chairs\", \"Filing cabinets\", \"Bookcases\"),\n  count = c(100, 80, 70, 60)\n)\n\n# Elements of the built-in data frame \nmy_df &lt;- office_df[1:4,]\n\n# Construct list with these different elements:\nmy_list &lt;- list(my_vector,my_matrix,my_df)\nmy_list\n\n[[1]]\n[1] 1 2 3 4\n\n[[2]]\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n[[3]]\n          product count\n1    Office desks   100\n2          Chairs    80\n3 Filing cabinets    70\n4       Bookcases    60"
  },
  {
    "objectID": "inclass1.html#preparation",
    "href": "inclass1.html#preparation",
    "title": "In Class 1",
    "section": "Preparation",
    "text": "Preparation\n\nlibrary (tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary (dplyr)\nraw_data &lt;- read.csv(\"./athlete_events.csv\")"
  },
  {
    "objectID": "inclass1.html#fundamentals",
    "href": "inclass1.html#fundamentals",
    "title": "In Class 1",
    "section": "Fundamentals",
    "text": "Fundamentals\n\nraw_data %&gt;% as_tibble()\n\n# A tibble: 271,116 × 15\n      ID Name     Sex     Age Height Weight Team  NOC   Games  Year Season City \n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;\n 1     1 A Dijia… M        24    180     80 China CHN   1992…  1992 Summer Barc…\n 2     2 A Lamusi M        23    170     60 China CHN   2012…  2012 Summer Lond…\n 3     3 Gunnar … M        24     NA     NA Denm… DEN   1920…  1920 Summer Antw…\n 4     4 Edgar L… M        34     NA     NA Denm… DEN   1900…  1900 Summer Paris\n 5     5 Christi… F        21    185     82 Neth… NED   1988…  1988 Winter Calg…\n 6     5 Christi… F        21    185     82 Neth… NED   1988…  1988 Winter Calg…\n 7     5 Christi… F        25    185     82 Neth… NED   1992…  1992 Winter Albe…\n 8     5 Christi… F        25    185     82 Neth… NED   1992…  1992 Winter Albe…\n 9     5 Christi… F        27    185     82 Neth… NED   1994…  1994 Winter Lill…\n10     5 Christi… F        27    185     82 Neth… NED   1994…  1994 Winter Lill…\n# ℹ 271,106 more rows\n# ℹ 3 more variables: Sport &lt;chr&gt;, Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\n\n#List of first 10 games by city\nraw_data %&gt;% \n  slice (1:10)%&gt;% \n  select(Games,City)\n\n         Games        City\n1  1992 Summer   Barcelona\n2  2012 Summer      London\n3  1920 Summer   Antwerpen\n4  1900 Summer       Paris\n5  1988 Winter     Calgary\n6  1988 Winter     Calgary\n7  1992 Winter Albertville\n8  1992 Winter Albertville\n9  1994 Winter Lillehammer\n10 1994 Winter Lillehammer\n\n\n\n#List of gold winners among basketball teams in 1972\ngold_winner &lt;- raw_data %&gt;%\n  filter(Year &gt;= \"1972\" & Year &lt;= \"1980\", Sport == \"Basketball\", Medal == \"Gold\")\nas.tibble(gold_winner)\n\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n\n\n# A tibble: 60 × 15\n      ID Name     Sex     Age Height Weight Team  NOC   Games  Year Season City \n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;\n 1  5173 \"Michel… M        20    190     77 Unit… USA   1976…  1976 Summer Mont…\n 2  8384 \"Olga F… F        21    168     67 Sovi… URS   1976…  1976 Summer Mont…\n 3  8384 \"Olga F… F        25    168     67 Sovi… URS   1980…  1980 Summer Mosk…\n 4  9779 \"Aleksa… M        20    200    100 Sovi… URS   1972…  1972 Summer Muni…\n 5  9783 \"Sergey… M        28    190     82 Sovi… URS   1972…  1972 Summer Muni…\n 6 10964 \"Vida B… F        23    190     91 Sovi… URS   1980…  1980 Summer Mosk…\n 7 13017 \"Aleksa… M        25    205    105 Sovi… URS   1972…  1972 Summer Muni…\n 8 16109 \"Willia… M        21    190     92 Unit… USA   1976…  1976 Summer Mont…\n 9 18483 \"Kennet… M        20    200    102 Unit… USA   1976…  1976 Summer Mont…\n10 23251 \"Kreimi… M        31    209     94 Yugo… YUG   1980…  1980 Summer Mosk…\n# ℹ 50 more rows\n# ℹ 3 more variables: Sport &lt;chr&gt;, Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\n\n#Show mean_ages by year with number of athletes data\nraw_data %&gt;% \n  group_by(Year) %&gt;%\n  summarize(mean_age = mean(Age, na.rm = TRUE), sd_age = sd(Age, na.rm =TRUE), ID = n()) %&gt;%\n  arrange(mean_age)\n\n# A tibble: 35 × 4\n    Year mean_age sd_age    ID\n   &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n 1  1896     23.6   4.69   380\n 2  1980     23.7   5.08  8937\n 3  1976     23.8   5.55 10502\n 4  1984     23.9   5.25 11588\n 5  1988     24.1   5.20 14676\n 6  1968     24.2   5.76 10479\n 7  1972     24.3   5.81 11959\n 8  1992     24.3   5.17 16413\n 9  1994     24.4   4.20  3160\n10  1996     24.9   5.50 13780\n# ℹ 25 more rows"
  },
  {
    "objectID": "inclass2.html",
    "href": "inclass2.html",
    "title": "In Class 2",
    "section": "",
    "text": "library (tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary (dplyr)\nlibrary (ggplot2)\nraw_data &lt;- read.csv(\"./athlete_events.csv\")\n\n\n#List of gold winners among basketball teams between 1972 and 1980\ngold_winner &lt;- raw_data %&gt;%\n  filter(Year &gt;= \"1972\" & Year &lt;= \"1980\", Sport == \"Basketball\", Medal == \"Gold\")\nas_tibble(gold_winner)\n\n# A tibble: 60 × 15\n      ID Name     Sex     Age Height Weight Team  NOC   Games  Year Season City \n   &lt;int&gt; &lt;chr&gt;    &lt;chr&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;\n 1  5173 \"Michel… M        20    190     77 Unit… USA   1976…  1976 Summer Mont…\n 2  8384 \"Olga F… F        21    168     67 Sovi… URS   1976…  1976 Summer Mont…\n 3  8384 \"Olga F… F        25    168     67 Sovi… URS   1980…  1980 Summer Mosk…\n 4  9779 \"Aleksa… M        20    200    100 Sovi… URS   1972…  1972 Summer Muni…\n 5  9783 \"Sergey… M        28    190     82 Sovi… URS   1972…  1972 Summer Muni…\n 6 10964 \"Vida B… F        23    190     91 Sovi… URS   1980…  1980 Summer Mosk…\n 7 13017 \"Aleksa… M        25    205    105 Sovi… URS   1972…  1972 Summer Muni…\n 8 16109 \"Willia… M        21    190     92 Unit… USA   1976…  1976 Summer Mont…\n 9 18483 \"Kennet… M        20    200    102 Unit… USA   1976…  1976 Summer Mont…\n10 23251 \"Kreimi… M        31    209     94 Yugo… YUG   1980…  1980 Summer Mosk…\n# ℹ 50 more rows\n# ℹ 3 more variables: Sport &lt;chr&gt;, Event &lt;chr&gt;, Medal &lt;chr&gt;\n\n\n\nggplot(gold_winner, aes(x = Height, y = Weight, color = as.character(Sex))) + geom_point()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "assignment_shiny.html",
    "href": "assignment_shiny.html",
    "title": "Assignment: Shiny",
    "section": "",
    "text": "About App\n\nThis app aims to help users analyze and explore olympics data interactively.\nThe visualization provides evolution of how the number of sportsperson in different age groups has varied over the years.\n\n\n\n\nCommand Line\nYou can run my shiny app using the following command.\n\nlibrary(shiny)\n\nshiny::runGitHub(\"https://github.com/pjournal/mef07-sezgia\", subdir = \"/app/app.R\")\n\n\n\nApp Link\nMy Shiny App\nAlso, you can try the app on Shinyapps."
  },
  {
    "objectID": "orassignment.html#business-case-summary",
    "href": "orassignment.html#business-case-summary",
    "title": "Operational Research Assignment",
    "section": "Business Case Summary",
    "text": "Business Case Summary\nThe swissQuant Group develops and delivers intelligent technology products for Risk Modelling & Analytics, Trading & Risk Management and Hedging & Procurement.\nIn this business case; their primary objective is to implement a solution designed to alter the process of suggesting personalized investment portfolios for private banking customers.\nThis solution aims to integrate customer-specific objectives, risk profiles, and available assets while adhering to the stringent policies and regulations governing the banking industry."
  },
  {
    "objectID": "orassignment.html#problem-description",
    "href": "orassignment.html#problem-description",
    "title": "Operational Research Assignment",
    "section": "Problem Description",
    "text": "Problem Description\nProblem Description: Structuring a portfolio by formulating it as a mathematical optimization problem and optimizing it with respect to target function in order to maximize the portfolio’s rate of return subject to risk limits.\nIn this business case; solution provider Gurabi solves a mixed-integer quadratic problem (MIQP).\nPortfolio optimization results in a MIQP as it is characterised by a quadratic objective function with 1,000 to 10,000 variables and almost as many additional linear conditions, and also some of the variables must only be represented as integer values.\nKey Considerations to choose Gurabi’s Solutions: Better solver performance, higher speed, the ability to scale the project demands, stability and reliability in solving complex problems, better quality compared to its alternatives."
  },
  {
    "objectID": "orassignment.html#solution-approach",
    "href": "orassignment.html#solution-approach",
    "title": "Operational Research Assignment",
    "section": "Solution Approach",
    "text": "Solution Approach\nIntegration Process of Gurabi’s Solution:\n\nCreation of a customer profile\nPresenting opportunities and risks interactively in the profile, applying stress tests to understand bank risks\nAdding customer-specific restrictions and general bank rules and creating a diverse set of conditions\nSolving a mathematical optimization model, optimizing the portfolio to maximize return within risk limits.\nPresenting the optimized portfolio, featuring various investment strategies, risks, and benefits"
  },
  {
    "objectID": "orassignment.html#benefits",
    "href": "orassignment.html#benefits",
    "title": "Operational Research Assignment",
    "section": "Benefits",
    "text": "Benefits\n\nEfficiency in Problem Solving: found solutions for 98% of feasible problems1 within 20 seconds, showcasing its efficiency in problem-solving.\nBetter Performance compared to Competitor: The competitor could achieve solution times of less than 20 seconds for only 38% of the models tested.\nOptimal Solutions: found the optimum solution for 90% of the test problems, surpassing the competitor’s performance, which could only achieve this for 55% of the problems.\nHigher Returns: 1% higher returns compared to another commercial solver in portfolio optimization, In 7% of feasible problems"
  },
  {
    "objectID": "orassignment.html#references",
    "href": "orassignment.html#references",
    "title": "Operational Research Assignment",
    "section": "References",
    "text": "References\nBusiness Case\nProven Techniques for Solving Financial Problems with Gurobi\nMixed Integer Programming Basics"
  },
  {
    "objectID": "orassignment.html#footnotes",
    "href": "orassignment.html#footnotes",
    "title": "Operational Research Assignment",
    "section": "",
    "text": "A feasible problem is defined as a portfolio optimization with at least one solution that fulfills all restrictions.\n\n↩︎"
  },
  {
    "objectID": "final.html#part-1-short-and-simple",
    "href": "final.html#part-1-short-and-simple",
    "title": "Final Exam",
    "section": "Part 1 Short and Simple",
    "text": "Part 1 Short and Simple\n\n1. Regulating AI\nI agree that unregulated AI poses ethical and security risks, necessitating regulations for societal trust. However, AI has societal impacts and has revolutionized various sectors. Strict regulations may also hinder innovation, but a balance is needed. As OpenAI leaders suggest, regulation is needed to allow development below a certain capability threshold. Regulations should not disadvantage small players. There is also a need for an international regulator body. I’ve found a proposal interesting, which is published in Lords Library UK, suggesting an AI lab established to research and test safe AI, avoiding harm to progress and launching major AI-talent programs. They also propose remodeling data as a public asset, needing thoughtful consideration.\n\n\n2. Progress on a Data Science Project\n\nDefine project objectives and establish topic expertise for meaningful data analysis.\nCollect and acquire relevant data sources, aligning with the data science lifecycle.\nConduct exploratory data analysis and refine project scope iteratively.\nChoose appropriate technology stack, integrating automation and predictive modeling.\nAddress data cleaning and preprocessing, ensuring data quality for accurate modeling.\nDevelop an automation framework and deploy solutions, emphasizing maintenance and testing.\nDocument the entire process for knowledge transfer and future enhancements.\nProvide training, ensure a smooth transition, and acknowledge the iterative nature of the project lifecycle.\n\n\n\n3. US Election Plot\nThis map illustrates the outcome of the U.S. presidential election on a state-by-state basis. The shading indicates the election winners, with darker blue representing states won by Hillary Clinton and darker red representing states won by Donald Trump.\nThe official results on election night initially showed Trump securing 306 electoral votes, while Clinton obtained 232. However, based on the data provided here, Trump received 305 electoral votes, and Clinton received 232. The discrepancy arises from the allocation of Maine’s electoral votes, where 4 votes were calculated for Clinton in this database. In reality, Maine awarded 3 electoral votes to Clinton and 1 to Trump, as the state allocates electoral votes proportionally by congressional district.\nThe final official results account for seven faithless electors, five Democratic and two Republican, resulting in Trump receiving a total of 304 electoral votes and Clinton 227.\n\n\nCode\nlibrary(dslabs)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf) # for spatial data\n\n\n\n\nCode\n# Define Database\ndata &lt;- results_us_election_2016\n\n#US states map is downloaded from ArcGIS Hub (51 states)\nstates &lt;- st_read(\"shapefile.geojson\") \n\n\nReading layer `States_shapefile' from data source \n  `/Users/sezgi/Documents/GitHub/mef07-sezgia/shapefile.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 51 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -178.2176 ymin: 18.92179 xmax: -66.96927 ymax: 71.40624\nGeodetic CRS:  WGS 84\n\n\nCode\n#Match the column names and input data of states in main datafile and shapefile\ncolnames(data)[colnames(data) == \"state\"] &lt;- \"State_Name\" \nstates$State_Name &lt;- tolower(states$State_Name)\ndata$State_Name &lt;- tolower(data$State_Name)\n\n#Merge the main datafile and shapefile\nmerged_data &lt;- merge(states, data, by.x = \"State_Name\", by.y = \"State_Name\")\n\n#Define winners \nmerged_data$winner &lt;- ifelse(merged_data$clinton &gt; merged_data$trump \n    &merged_data$clinton &gt; merged_data$others, \"Clinton\",\nifelse(merged_data$trump &gt; merged_data$clinton \n    &merged_data$trump &gt; merged_data$others, \"Trump\", \"Others\"))\n\n# Calculate the sum of electoral votes for each winner\nsum_votes &lt;- merged_data %&gt;%\n  group_by(winner) %&gt;%\n   mutate(total_electoral_votes = sum(electoral_votes))\n\n# Plot the map using ggplot\nggplot() +\n  geom_sf(data = merged_data, aes(fill = winner), color = \"lightyellow\", lwd = 0.2) +\n  scale_fill_manual(name = \"Winner\", values = c(\"Clinton\" = \"darkblue\", \n                    \"Trump\" = \"darkred\", \"Others\" = \"lightyellow\")) +\n  theme_minimal() +\n  ggtitle(\"Election Winners by State in 2016\") +\n  labs(fill = \"Winner\") +\n geom_text(data = sum_votes %&gt;% filter(winner %in% c(\"Clinton\", \"Trump\")),\n            aes(label = paste(winner, \"\\nTotal Electoral Votes:\", total_electoral_votes), \n                x = Inf, y = Inf, color = winner),\n            size = 3, hjust = 1, vjust = ifelse(sum_votes$winner == \"Clinton\", 2,4)) +\n  scale_color_manual(values = c(\"Clinton\" = \"darkblue\", \"Trump\" = \"darkred\")) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "final.html#part-2-extending-your-group-project",
    "href": "final.html#part-2-extending-your-group-project",
    "title": "Final Exam",
    "section": "Part 2 Extending Your Group Project",
    "text": "Part 2 Extending Your Group Project\nPurpose: The purpose of this analysis is to examine the textile sector, evaluate the degree of value addition of the commodities listed under this industry and develop strategic recommendations.\nMethod: Technical textiles, which are high value-added products requiring advanced technology, are rapidly gaining prominence over traditional textiles in Turkey. I have collected commodity codes of technical textiles from a research study and filtered in this database to illustrate some selected technical textile product types’ revenue performance and their count of trade partners.\nKey Findings: Major revenue streams among textile commodities are cottons, yarns and fibers which are non-processed raw materials. Turkey should diversify these sources and focuse more on technical textiles. The presented illustration details Turkey’s existing export commodities of technical textiles, suggesting areas for expanding trade and revenue. Significant among these are textile fabrics treated with plastics, processed nonwovens, labels, badges, and various textile articles, alongside garments.\n\n\nCode\n# Load Datasets\nloaded_datasets &lt;- readRDS(\"wits_data.rds\")\nread_wits_turkey_data_only &lt;- \nloaded_datasets$wits_turkey_data_only\nread_wits_turkey_data_with_partners &lt;- loaded_datasets$wits_turkey_data_with_partners\n\n\n\n\nCode\n# Define dataset\ntextile_data &lt;- read_wits_turkey_data_with_partners \n\n# Filter for section code 11\ntextile_data &lt;- textile_data %&gt;% \n  filter(section_code == 11) #Code11 is textile\n\n# Extract the first four digits of each commodity code\ntextile_data$commodity_code_3d &lt;- substr(textile_data$commodity_code, 1, 4)\n\n# Extract the first 20 letters of commodity name\ntextile_data$commodity_name_short &lt;- substr(textile_data$commodity_name, 1, 20)\n\n# Count unique partners for each commodity code\npartner_count &lt;- textile_data %&gt;%\n  group_by(commodity_code_3d) %&gt;%\n  summarize(partner_count = n_distinct(partner_name))\n\n# Aggregate trade_value_usd_imp and get short commodity names for each commodity code\ntrade_values &lt;- textile_data %&gt;%\n  group_by(commodity_code_3d) %&gt;%\n  summarize(trade_value_usd_exp = sum(trade_value_usd_imp/1e9, na.rm = TRUE),\n            commodity_name_short = first(commodity_name_short)) # Use shortened name\n\n# Merging partner_count with trade_values\nmerged_data &lt;- merge(trade_values, partner_count, by = \"commodity_code_3d\")\n\n# Select technical textile commodity types based on trade_value_usd_exp\nselected_commodities &lt;- merged_data %&gt;%\n filter(commodity_code_3d %in% c( \"5601\", \"5602\", \"5603\",\"5605\",\"5607\",\n                                  \"5806\",\"5807\",\"5902\",\"5903\",\"6210\"))\n\n# Create a treemap\nggplot(selected_commodities, aes(area = trade_value_usd_exp, fill = commodity_code_3d,\n    label = paste(commodity_name_short, \"\\n\", round(trade_value_usd_exp,1),\n    \"bn $\", \"\\n Trade Partners:\", partner_count))) +\n  geom_treemap() +\n  geom_treemap_text(fontface = \"italic\", colour = \"white\", place = \"centre\", grow = TRUE) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Turkey Exports - Technical Textiles\")"
  },
  {
    "objectID": "final.html#part-3-welcome-to-real-life",
    "href": "final.html#part-3-welcome-to-real-life",
    "title": "Final Exam",
    "section": "Part 3 Welcome to Real Life",
    "text": "Part 3 Welcome to Real Life\nPurpose: This analysis aims to review the frequency of maintenance and breakdowns at Entek Electricity Generation Company’s power plants in November. It will categorize these incidents by plant type and cause, assess downtime duration and evaluate the capacity load factor and installed power at the time of each case.\nMethod: Maintenance & Breakdown data files are combined manually in Excel file before creating the RData file.\nProject Database: RData Link\nKey Findings:\nIn November, Entek encountered 7 breakdowns and 1 maintenance-related downtime across their power plants. Specifically, its gas turbine in İzmit experienced 2 downtimes – one due to maintenance and the other a breakdown.\nThe most significant downtime occurred due to a gas turbine failure, while other instances were primarily linked to issues with the source water program.\nRegarding capacity load factors, the Kumköy hydroplant was the most impacted during downtime, showing the highest reduction in utilization. This was followed closely by the Kepezkaya hydro power plant and the Gas Turbine in İzmit.\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\n\n# Read Excel file\nepias_data_file &lt;- readxl::read_excel(\"./epiasdata.xlsx\")\n\n# Save the data as RData\nsave(epias_data_file, file = \"epiasDB.RData\")\ngetwd()\n\n\n[1] \"/Users/sezgi/Documents/GitHub/mef07-sezgia\"\n\n\n\n\nCode\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\n\n\nCode\n# Load the data from RData file\nload(\"epiasDB.RData\")\npower_data &lt;- epias_data_file \n\n#Change column names\ncolnames(power_data) &lt;- c(\"orgName\", \"powerPlantName\", \"relatedUnit_uevcb\",\n                          \"caseStartDate\", \"caseEndDate\", \"installedPower\", \n                          \"capacityatCaseTime\",\"reason\", \"maintenanceorbreakdown\")\n\n# Filter for ENTEK ELEKTRİK ÜRETİMİ A.Ş.\nentek_data &lt;- filter(power_data, orgName == \"ENTEK ELEKTRİK ÜRETİMİ A.Ş.\")\n# Create the new column 'plantType'\nentek_data &lt;- entek_data %&gt;%\n  mutate(plantType = case_when(\n    grepl(\"HES\", relatedUnit_uevcb) ~ \"Hydro Power Plant\",\n    grepl(\"TERMİK SANTRAL\", relatedUnit_uevcb) ~ \"Gas Turbine\",\n    TRUE ~ NA_character_  \n  ))\n# Change column names\nentek_data &lt;- entek_data %&gt;% \n  mutate(\n    reason= case_when(\n      str_detect(reason, \"^MEMBA\") ~ \"PlantFailure\",\n      str_detect(reason, \"^SANTRAL\") ~ \"PlantFailure\",\n      str_detect(reason, \"^gelen su azalışı\") ~ \"WaterProblem\",\n      str_detect(reason, \"^memba santrali programı\") ~ \"SourceWaterProgram\",\n      str_detect(reason, \"^GT3\") ~ \"GasUnitFailure\",\n      str_detect(reason, \"^KEPEZKAYA\") ~ \"ScheduledMaintenance\",\n      str_detect(reason, \"^DAMLAPINAR\") ~ \"ScheduledMaintenance\",\n      str_detect(reason, \"^Memba\") ~ \"SourceWaterProgram\",\n      TRUE ~ as.character(reason)\n    )\n  )\n# Convert caseStartDate and caseEndDate to datetime objects\nentek_data$caseStartDate &lt;- ymd_hms(entek_data$caseStartDate, truncated = 3)\nentek_data$caseEndDate &lt;- ymd_hms(entek_data$caseEndDate, truncated = 3)\n# Extract date and time components and add them as new columns \nentek_data &lt;- entek_data %&gt;%\n  mutate(\n    start_date = as.Date(caseStartDate),\n    end_date = as.Date(caseEndDate),\n    start_time = ifelse(!is.na(caseStartDate), format(caseStartDate, \"%H:%M:%S\"), NA),\n    end_time = ifelse(!is.na(caseEndDate), format(caseEndDate, \"%H:%M:%S\"), NA)\n  )\n# Convert start_time and end_time to POSIXct\nentek_data$start_time &lt;- as.POSIXct(paste(entek_data$start_date, entek_data$start_time))\nentek_data$end_time &lt;- as.POSIXct(paste(entek_data$end_date, entek_data$end_time))\n# Calculate the time difference and convert it to a period (duration)\nentek_data &lt;- entek_data %&gt;%\n  mutate(time_difference = difftime(end_time, start_time, units = \"hours\"))\n  entek_data$time_difference_numeric &lt;- as.numeric(entek_data$time_difference, \n                                       units = \"hours\")\n# Add a new column showing loadfactoratCasetime\nentek_data &lt;- entek_data %&gt;%\n  mutate(loadfactoratCaseTime = entek_data$capacityatCaseTime/entek_data$installedPower)\n\nggplot(entek_data, aes(x = plantType, fill = maintenanceorbreakdown)) +\n  geom_histogram(stat = \"count\", position = \"dodge\") +\n  labs(x = \"Plant Type\", y = \"Count of Maintenance/Breakdown\") +\n  ggtitle(\"Entek's Maintenances & Breakdowns in November\") +\n  theme_minimal()  +\n  theme(text = element_text(size = 10))\n\n\n\n\n\n\n\nCode\n# Filter data according to capacity at case time and summarize\nfiltered_data_td &lt;- entek_data %&gt;%\n  filter(capacityatCaseTime != 0) %&gt;%\n  group_by(reason) %&gt;%\n  summarize(time_difference_numeric_total = sum(time_difference_numeric))\n\n# Plot \nggplot(filtered_data_td, aes(x = reason, y = time_difference_numeric_total)) +\n  geom_bar(stat = \"identity\", fill = \"coral\") +\n  labs(x = \"Reason\", y = \"Downtime (in hours)\") +\n  ggtitle(\"Downtime by Reason\")+\n  theme_minimal()+\n  theme(text = element_text(size = 10))\n\n\n\n\n\n\n\nCode\n# Filter data and summarize\nfiltered_data_pp &lt;- entek_data %&gt;%\n  filter(capacityatCaseTime != 0, maintenanceorbreakdown == \"Breakdown\") %&gt;%\n  group_by(powerPlantName) %&gt;%\n  summarize(installed_Power = max(installedPower),load_factor = max(loadfactoratCaseTime), .groups = \"drop\")\n  \n#Plot\nggplot(filtered_data_pp, aes(x = powerPlantName)) +\n  # Bar plot for installedPower\n  geom_bar(aes(y = installed_Power), stat = \"identity\", fill = \"skyblue3\") +\n  # Line plot for loadfactoratCaseTime\n  geom_line(aes(y = load_factor * 100, group = 1), color = \"coral\", size = 1) +\n  # Secondary axis for loadfactoratCaseTime\n  scale_y_continuous(sec.axis = sec_axis(~ . / 100, name = \"Load Factor at Case Time\")) +\n  labs(x = \"Power Plant Name\", y = \"Installed Power (Max)\") +\n  theme_minimal() +\n  ggtitle(\"Installed Power and Load Factor at Case Time by Power Plant\")+\n  theme(text = element_text(size = 10))"
  }
]